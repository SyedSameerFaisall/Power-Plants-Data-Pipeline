{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7dc69fc7-fac2-4231-b088-04f058154fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "class PowerPlants(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.database_file = 'database.csv'\n",
    "        # Simple country name mapping\n",
    "        self.country_map = {\n",
    "            'FR': 'France',\n",
    "            'GB': 'Great Britain'\n",
    "        }\n",
    "\n",
    "    def _get_full_country_name(self, country_code_or_name):\n",
    "        \"\"\"\n",
    "        Converts a country identifier (code or name) to a standardized full name.\n",
    "        \"\"\"\n",
    "        return self.country_map.get(str(country_code_or_name).upper())\n",
    "    \n",
    "    def load_new_data_from_file(self, file_path: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Loads and processes data from a specified CSV file.\n",
    "        Handles missing data, maps country codes, and adds metadata.\n",
    "        \"\"\"\n",
    "        if not os.path.exists(file_path):\n",
    "            raise FileNotFoundError(f\"Input file not found: {file_path}\")\n",
    "            \n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        rename_map = {\n",
    "            'Date': 'date',\n",
    "            'Site Name': 'SiteName',\n",
    "            'Country': 'country'\n",
    "        }\n",
    "        df.rename(columns=lambda c: rename_map.get(c, c.strip()), inplace=True)\n",
    "\n",
    "        if 'country' in df.columns:\n",
    "            df['country'] = df['country'].apply(self._get_full_country_name)\n",
    "        else:\n",
    "            if 'country' not in df.columns:\n",
    "                 df['country'] = \"Unknown\"\n",
    "\n",
    "        # Date Processing\n",
    "        if 'date' in df.columns:\n",
    "            df['date'] = pd.to_datetime(df['date'], dayfirst=True).dt.strftime('%Y-%m-%d')\n",
    "        else:\n",
    "            raise ValueError(f\"Date column is missing in the input file: {file_path}\")\n",
    "\n",
    "        if 'Technology' not in df.columns:\n",
    "            if 'wind_plants.csv' in file_path:\n",
    "                df['Technology'] = 'Wind'\n",
    "            elif 'gas_plants.csv' in file_path or 'gas_fr_plants.csv' in file_path:\n",
    "                df['Technology'] = 'Gas'\n",
    "            else:\n",
    "                df['Technology'] = 'Unknown'\n",
    "\n",
    "        # Volume Processing\n",
    "        if 'Volume' in df.columns:\n",
    "            df['Volume'] = pd.to_numeric(df['Volume'], errors='coerce').fillna(0)\n",
    "\n",
    "        # Add Metadata Columns\n",
    "        df['updatetime'] = pd.Timestamp.now(tz=None) # Timezone naive timestamp\n",
    "        df['updatedby'] = 'petroineos' # As per example in image\n",
    "\n",
    "        # Final Column Selection and Order based on the example output for get_data_from_database\n",
    "        final_columns_order = ['country', 'date', 'SiteName', 'Technology', 'updatedby', 'updatetime', 'Volume']\n",
    "\n",
    "        df = df[final_columns_order]\n",
    "        return df\n",
    "\n",
    "    def save_new_data(self, input_data: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Saves the loaded and processed DataFrame to the database CSV file.\n",
    "        Appends if the file exists, creates with header if it doesn't.\n",
    "        \"\"\"\n",
    "        if not isinstance(input_data, pd.DataFrame):\n",
    "            raise TypeError(\"input_data must be a pandas DataFrame.\")\n",
    "\n",
    "        file_exists = os.path.exists(self.database_file)\n",
    "        input_data.to_csv(self.database_file, mode='a', header=not file_exists, index=False)\n",
    "\n",
    "    def _read_database(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Helper function to read the database CSV file.\n",
    "        Handles file not existing, empty file, and ensures basic column types.\n",
    "        \"\"\"\n",
    "        expected_cols = ['country', 'date', 'SiteName', 'Technology', 'updatedby', 'updatetime', 'Volume']\n",
    "        \n",
    "        if not os.path.exists(self.database_file):\n",
    "            return pd.DataFrame(columns=expected_cols)\n",
    "        \n",
    "        try:\n",
    "            db_df = pd.read_csv(self.database_file)\n",
    "            if db_df.empty and not list(db_df.columns): # File exists but is truly empty or only headers of empty table\n",
    "                 return pd.DataFrame(columns=expected_cols)\n",
    "        except pd.errors.EmptyDataError: # File is completely empty (no content at all)\n",
    "            return pd.DataFrame(columns=expected_cols)\n",
    "\n",
    "        # Ensure essential columns exist, fill with NA/default if not\n",
    "        for col in expected_cols:\n",
    "            if col not in db_df.columns:\n",
    "                if col == 'Volume':\n",
    "                    db_df[col] = 0.0\n",
    "                elif col in ['date', 'updatetime']:\n",
    "                    db_df[col] = pd.NaT\n",
    "                else:\n",
    "                    db_df[col] = pd.NA # Use pandas NA for general missing string/object data\n",
    "\n",
    "        # Select only expected columns in the defined order\n",
    "        db_df = db_df[expected_cols]\n",
    "\n",
    "        # Convert data types, coercing errors\n",
    "        db_df['date'] = pd.to_datetime(db_df['date'], errors='coerce')\n",
    "        db_df['updatetime'] = pd.to_datetime(db_df['updatetime'], errors='coerce')\n",
    "        db_df['Volume'] = pd.to_numeric(db_df['Volume'], errors='coerce').fillna(0)\n",
    "        \n",
    "        # Ensure string columns are strings, to handle potential all-NA columns read as float etc.\n",
    "        for col in ['country', 'SiteName', 'Technology', 'updatedby']:\n",
    "            if col in db_df.columns:\n",
    "                 db_df[col] = db_df[col].astype(str).replace('nan', pd.NA).replace('<NA>', pd.NA)\n",
    "\n",
    "        return db_df\n",
    "\n",
    "    def get_data_from_database(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Returns the most recently updated data for every symbol (SiteName, date combination)\n",
    "        from the database.\n",
    "        \"\"\"\n",
    "        db_df = self._read_database()\n",
    "        \n",
    "        if db_df.empty or 'updatetime' not in db_df.columns or 'SiteName' not in db_df.columns or 'date' not in db_df.columns:\n",
    "            # Return empty df with correct columns if db is empty or key columns missing\n",
    "             expected_cols = ['country', 'date', 'SiteName', 'Technology', 'updatedby', 'updatetime', 'Volume']\n",
    "             return pd.DataFrame(columns=expected_cols)\n",
    "\n",
    "        # Remove rows where key identifiers or updatetime are NaT/NaN after conversion\n",
    "        db_df.dropna(subset=['SiteName', 'date', 'updatetime'], inplace=True)\n",
    "        if db_df.empty:\n",
    "            expected_cols = ['country', 'date', 'SiteName', 'Technology', 'updatedby', 'updatetime', 'Volume']\n",
    "            return pd.DataFrame(columns=expected_cols)\n",
    "\n",
    "        # Sort by SiteName, date, and then by updatetime descending to get the latest entry first\n",
    "        # for each (SiteName, date) group.\n",
    "        latest_df = db_df.sort_values(by=['SiteName', 'date', 'updatetime'], ascending=[True, True, False])\n",
    "        \n",
    "        # Drop duplicates based on (SiteName, date), keeping the first occurrence (which is the most recent)\n",
    "        result_df = latest_df.drop_duplicates(subset=['SiteName', 'date'], keep='first').copy()\n",
    "        \n",
    "        # Format columns as per the example output\n",
    "        result_df['date'] = pd.to_datetime(result_df['date']).dt.strftime('%Y-%m-%d')\n",
    "        result_df['Volume'] = result_df['Volume'].apply(lambda x: f\"{x:.6f}\")\n",
    "        \n",
    "        # Ensure final column order\n",
    "        final_columns_order = ['country', 'date', 'SiteName', 'Technology', 'updatedby', 'updatetime', 'Volume']\n",
    "        result_df = result_df[final_columns_order]\n",
    "        \n",
    "        return result_df\n",
    "\n",
    "    def aggregate_data_to_monthly(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Returns a DataFrame with monthly average, min, and max Volume for each plant.\n",
    "        The format matches the structure seen in 'month_average_min_max.png'. [cite: 15]\n",
    "        \"\"\"\n",
    "        current_data = self.get_data_from_database()\n",
    "        \n",
    "        if current_data.empty:\n",
    "            return pd.DataFrame() # Return empty DataFrame if no data\n",
    "\n",
    "        # Convert Volume back to numeric and date to datetime for calculations\n",
    "        current_data['Volume'] = pd.to_numeric(current_data['Volume'], errors='coerce')\n",
    "        current_data['date'] = pd.to_datetime(current_data['date'], errors='coerce')\n",
    "        \n",
    "        current_data.dropna(subset=['Volume', 'date', 'SiteName'], inplace=True)\n",
    "        if current_data.empty:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        # Group by SiteName and month (first day of month), then aggregate\n",
    "        # Using a dictionary for agg ensures column names 'Min', 'Mean', 'Max'\n",
    "        monthly_agg = current_data.groupby(\n",
    "            ['SiteName', pd.Grouper(key='date', freq='MS')] \n",
    "        )['Volume'].agg(Min='min', Mean='mean', Max='max')\n",
    "        \n",
    "        if monthly_agg.empty:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        # Unstack 'SiteName' to transform it into column levels\n",
    "        result_df = monthly_agg.unstack(level='SiteName')\n",
    "        \n",
    "        # Swap levels to get (SiteName, Stat) for easier sorting and final naming\n",
    "        result_df = result_df.swaplevel(0, 1, axis=1)\n",
    "        \n",
    "        # Sort columns: first by SiteName (alphabetically), then by Stat (Min, Mean, Max order)\n",
    "        result_df = result_df.sort_index(axis=1, level=0, sort_remaining=False) \n",
    "                                       \n",
    "        # Flatten the multi-level column names to 'SiteName Stat' format\n",
    "        result_df.columns = [f\"{site} {stat}\" for site, stat in result_df.columns]\n",
    "        \n",
    "        # Format the index (date) to 'YYYY-MM-DD' string\n",
    "        result_df.index = result_df.index.strftime('%Y-%m-%d')\n",
    "        \n",
    "        return result_df\n",
    "\n",
    "    def aggregate_data_to_country(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Returns a DataFrame with the total power production (Volume) by country and technology type.\n",
    "        Matches structure of 'country_sum.png'. [cite: 18]\n",
    "        \"\"\"\n",
    "        current_data = self.get_data_from_database()\n",
    "        \n",
    "        if current_data.empty:\n",
    "            return pd.DataFrame(columns=['country', 'Technology', 'Volume'])\n",
    "\n",
    "        # Convert Volume back to numeric for calculation\n",
    "        current_data['Volume'] = pd.to_numeric(current_data['Volume'], errors='coerce')\n",
    "        current_data.dropna(subset=['Volume', 'country', 'Technology'], inplace=True)\n",
    "\n",
    "        if current_data.empty:\n",
    "            return pd.DataFrame(columns=['country', 'Technology', 'Volume'])\n",
    "\n",
    "        # Group by 'country' and 'Technology', then sum 'Volume'\n",
    "        country_agg_df = current_data.groupby(['country', 'Technology'])['Volume'].sum().reset_index()\n",
    "        \n",
    "        return country_agg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cf30352e-633a-43d1-8431-714b23edea4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a PowerPLants object\n",
    "pp = PowerPlants()\n",
    "\n",
    "# Load and save data sequentially as per instructions\n",
    "new_data_wind = pp.load_new_data_from_file('wind_plants.csv')\n",
    "pp.save_new_data(new_data_wind)\n",
    "\n",
    "new_data_gas = pp.load_new_data_from_file('gas_plants.csv')\n",
    "pp.save_new_data(new_data_gas)\n",
    "\n",
    "new_data_gas_fr = pp.load_new_data_from_file('gas_fr_plants.csv')\n",
    "pp.save_new_data(new_data_gas_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1c78dea4-5ca8-4837-bebe-10075276eeec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Recently Updated Data (get_data_from_database)\n",
      "            country        date    SiteName Technology   updatedby  \\\n",
      "2394         France  2024-01-01    Blenod-5        Gas  petroineos   \n",
      "2395         France  2024-01-02    Blenod-5        Gas  petroineos   \n",
      "2396         France  2024-01-03    Blenod-5        Gas  petroineos   \n",
      "2397         France  2024-01-04    Blenod-5        Gas  petroineos   \n",
      "2398         France  2024-01-05    Blenod-5        Gas  petroineos   \n",
      "...             ...         ...         ...        ...         ...   \n",
      "3826  Great Britain  2025-04-21  Pembroke-2        Gas  petroineos   \n",
      "3827  Great Britain  2025-04-22  Pembroke-2        Gas  petroineos   \n",
      "3828  Great Britain  2025-04-23  Pembroke-2        Gas  petroineos   \n",
      "3829  Great Britain  2025-04-24  Pembroke-2        Gas  petroineos   \n",
      "3830  Great Britain  2025-04-25  Pembroke-2        Gas  petroineos   \n",
      "\n",
      "                     updatetime       Volume  \n",
      "2394 2025-05-29 10:39:35.435734  6753.000000  \n",
      "2395 2025-05-29 10:39:35.435734  3896.000000  \n",
      "2396 2025-05-29 10:39:35.435734  3636.000000  \n",
      "2397 2025-05-29 10:39:35.435734  5138.000000  \n",
      "2398 2025-05-29 10:39:35.435734  5265.000000  \n",
      "...                         ...          ...  \n",
      "3826 2025-05-29 10:39:35.542306  8301.000000  \n",
      "3827 2025-05-29 10:39:35.542306  5138.000000  \n",
      "3828 2025-05-29 10:39:35.542306  8662.000000  \n",
      "3829 2025-05-29 10:39:35.542306  5324.000000  \n",
      "3830 2025-05-29 10:39:35.542306  6165.000000  \n",
      "\n",
      "[2394 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"Most Recently Updated Data (get_data_from_database)\")\n",
    "latest_data = pp.get_data_from_database()\n",
    "print(latest_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b4f047c5-1330-424a-8994-51ec11516f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monthly Aggregated Data (aggregate_data_to_monthly) ---\n",
      "            Blenod-5 Min  Blenod-5 Mean  Blenod-5 Max  Hornsea-1 Min  \\\n",
      "date                                                                   \n",
      "2024-01-01        3295.0    5198.806452        6890.0      44.937929   \n",
      "2024-02-01        3489.0    4889.896552        6895.0       9.973714   \n",
      "2024-03-01        3122.0    4752.774194        6399.0      34.240333   \n",
      "2024-04-01        3235.0    4988.466667        6970.0      67.202179   \n",
      "2024-05-01        3059.0    5012.032258        6898.0      14.319806   \n",
      "2024-06-01        3083.0    4928.666667        6870.0      16.042355   \n",
      "2024-07-01        3115.0    4933.677419        6680.0       8.136290   \n",
      "2024-08-01        3104.0    5296.258065        6973.0       6.695016   \n",
      "2024-09-01        3110.0    4858.066667        6922.0      24.260159   \n",
      "2024-10-01        3061.0    5365.160000        6973.0      75.917168   \n",
      "2024-11-01        3108.0    4912.733333        6942.0      10.153305   \n",
      "2024-12-01        3087.0    4981.000000        6985.0       4.362489   \n",
      "2025-01-01        3088.0    5281.548387        6902.0       8.661232   \n",
      "2025-02-01        3170.0    4888.928571        6659.0      61.197204   \n",
      "2025-03-01        3246.0    4973.387097        6910.0      38.246157   \n",
      "2025-04-01        3156.0    4912.200000        6924.0      18.720171   \n",
      "\n",
      "            Hornsea-1 Mean  Hornsea-1 Max  Hornsea-2 Min  Hornsea-2 Mean  \\\n",
      "date                                                                       \n",
      "2024-01-01      502.454543     900.648050      85.603428      447.211079   \n",
      "2024-02-01      535.210353     980.763621      35.733954      437.902354   \n",
      "2024-03-01      432.654207     864.461415     122.681263      592.607677   \n",
      "2024-04-01      561.504570     995.133071      37.514079      504.877587   \n",
      "2024-05-01      431.650067     913.805516      16.694314      536.694996   \n",
      "2024-06-01      384.724509     852.995514       1.797161      387.852090   \n",
      "2024-07-01      471.688183     944.258261      13.206362      510.198669   \n",
      "2024-08-01      627.744512     988.355244      37.231691      474.907802   \n",
      "2024-09-01      474.785256     945.447225      80.138479      466.750342   \n",
      "2024-10-01      524.710537     990.985647      43.367492      520.673636   \n",
      "2024-11-01      516.710339     958.617373      47.214722      497.489315   \n",
      "2024-12-01      394.649258     948.631747      43.528442      501.604184   \n",
      "2025-01-01      521.896565     944.124280      20.682620      503.262437   \n",
      "2025-02-01      519.999043     975.022266      20.730174      562.308871   \n",
      "2025-03-01      522.404662     975.353766      46.351723      529.038269   \n",
      "2025-04-01      452.714035     999.697495      38.948111      551.854866   \n",
      "\n",
      "            Hornsea-2 Max  Pembroke-1 Min  Pembroke-1 Mean  Pembroke-1 Max  \\\n",
      "date                                                                         \n",
      "2024-01-01     892.386165          5390.0      7092.903226          8905.0   \n",
      "2024-02-01     994.618512          5222.0      6738.620690          8970.0   \n",
      "2024-03-01     979.909946          5196.0      7499.322581          8963.0   \n",
      "2024-04-01     999.165096          5251.0      6946.566667          8941.0   \n",
      "2024-05-01     962.658133          5009.0      7211.290323          8938.0   \n",
      "2024-06-01     979.952783          5001.0      7003.300000          8978.0   \n",
      "2024-07-01     850.887204          5077.0      7052.580645          8983.0   \n",
      "2024-08-01     999.000373          5049.0      7203.032258          8977.0   \n",
      "2024-09-01     992.225257          5149.0      7382.333333          8925.0   \n",
      "2024-10-01     988.350146          5162.0      7202.129032          8923.0   \n",
      "2024-11-01     979.579498          5053.0      6838.300000          8975.0   \n",
      "2024-12-01     987.308364          5026.0      7167.064516          8798.0   \n",
      "2025-01-01     981.596497          5151.0      6923.258065          8964.0   \n",
      "2025-02-01     980.890989          5015.0      6694.535714          8844.0   \n",
      "2025-03-01     905.421642          5118.0      6819.548387          8977.0   \n",
      "2025-04-01     978.341302          5452.0      7011.880000          8814.0   \n",
      "\n",
      "            Pembroke-2 Min  Pembroke-2 Mean  Pembroke-2 Max  \n",
      "date                                                         \n",
      "2024-01-01          5074.0      7195.096774          8941.0  \n",
      "2024-02-01          5051.0      6878.551724          8955.0  \n",
      "2024-03-01          5094.0      6605.806452          8685.0  \n",
      "2024-04-01          5167.0      7142.633333          8845.0  \n",
      "2024-05-01          5039.0      6759.806452          8888.0  \n",
      "2024-06-01          5247.0      7368.933333          8934.0  \n",
      "2024-07-01          5017.0      7057.483871          8981.0  \n",
      "2024-08-01          5262.0      7455.225806          8978.0  \n",
      "2024-09-01          5009.0      6596.333333          8931.0  \n",
      "2024-10-01          5101.0      6711.483871          8909.0  \n",
      "2024-11-01          5128.0      6970.233333          8934.0  \n",
      "2024-12-01          5142.0      6912.483871          8984.0  \n",
      "2025-01-01          5167.0      7029.096774          8750.0  \n",
      "2025-02-01          5491.0      7422.107143          8732.0  \n",
      "2025-03-01          5252.0      7233.677419          8883.0  \n",
      "2025-04-01          5115.0      6965.360000          8845.0  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Monthly Aggregated Data (aggregate_data_to_monthly) ---\")\n",
    "monthly_data = pp.aggregate_data_to_monthly()\n",
    "print(monthly_data)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cb0839cf-d8f1-4d92-8396-31dde7c4bb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country Aggregated Data (aggregate_data_to_country)\n",
      "         country Technology        Volume\n",
      "0         France        Gas  2.379583e+06\n",
      "1  Great Britain        Gas  6.768124e+06\n",
      "2  Great Britain      Wind   4.753565e+05\n"
     ]
    }
   ],
   "source": [
    "print(\"Country Aggregated Data (aggregate_data_to_country)\")\n",
    "country_data = pp.aggregate_data_to_country()\n",
    "print(country_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
